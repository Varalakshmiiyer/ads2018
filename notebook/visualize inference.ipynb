{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import chainer\n",
    "import numpy as np\n",
    "import chainer.functions as F\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('script/')\n",
    "from train import DatasetOCR, TextCNN, TextLSTM, NonVisualNet, Net, my_converter, AttentionNetWTL, word_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "norm = Normalize(vmin=0.0, vmax=2.0)\n",
    "\n",
    "import matplotlib.colors\n",
    "cmap = plt.get_cmap('cool')\n",
    "\n",
    "\n",
    "    \n",
    "def get_word_vis_html(att_val, words):\n",
    "\n",
    "    word_tmp = '''\n",
    "    <p style=\"display:inline;background-color:{0};font-size:12pt;color:#F2F2F2;font-weight:lighter;font-family:verdata;\">{1}</p>\n",
    "    '''\n",
    "\n",
    "    col_items = ''\n",
    "    for a, w in zip(att_val, words):\n",
    "        col_items += word_tmp.format(matplotlib.colors.to_hex(cmap(a)), w)\n",
    "        \n",
    "    return col_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ocr_att(ocr, act, rsn):\n",
    "    ya_emb = model.lng_net.word_embedding(act)\n",
    "    yr_emb = model.lng_net.word_embedding(rsn)        \n",
    "    yocr_emb = model.lng_net.word_embedding(ocr)\n",
    "    yocr_emb = F.repeat(yocr_emb, 15, axis=0)\n",
    "\n",
    "    # action feat\n",
    "    h_act = model.lng_net(act)\n",
    "\n",
    "    # reason feat\n",
    "    h_rsn = model.lng_net(rsn)\n",
    "\n",
    "    # attention over ocr words (action)\n",
    "    _, a_att = word_attention(yocr_emb, ya_emb)\n",
    "\n",
    "    # attention over ocr words (reason)\n",
    "    _, r_att = word_attention(yocr_emb, yr_emb)\n",
    "    \n",
    "    return a_att, r_att\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_html(img_id, a_att_array, r_att_array, raw_ocr, desc, sort_i):\n",
    "    table_tmp = '''\n",
    "    <table align=\"left\",width=\"50%%\">\n",
    "      <tr>\n",
    "        <th>%s</th>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <th>%s</th>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <th>%s</th>\n",
    "      </tr>\n",
    "    </table>\n",
    "    '''\n",
    "\n",
    "    img_tmpl = '''<img src=\"http://localhost:8888/files/data/test_images/%s\" width=\"200\" height=\"200\">'''\n",
    "    \n",
    "    html = ''\n",
    "\n",
    "    for im_i, act_a, rsn_a, o, des, s_i in zip(img_id, a_att_array, r_att_array, raw_ocr, desc, sort_i):\n",
    "        desc_top1 = des[s_i[0]]\n",
    "        act_row_html = get_word_vis_html(act_a[s_i[0]], o)\n",
    "        rsn_row_html = get_word_vis_html(rsn_a[s_i[0]], o)\n",
    "\n",
    "        img_html = img_tmpl % im_i\n",
    "        word_html = act_row_html + '<br>' + rsn_row_html\n",
    "        desc_html = '<p style=\"display:inline;font-size:12pt;\">%s</p>' % desc_top1\n",
    "\n",
    "        html += table_tmp % (img_html, desc_html, word_html)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'output/checkpoint/ocr+vis20180628-153515/'\n",
    "device = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = json.load(open(os.path.join(model_dir, 'args')))\n",
    "\n",
    "chainer.config.remove_stopwords = args['remove_stopwords']\n",
    "\n",
    "test = DatasetOCR('test', ocr_type=args['ocr_type'])\n",
    "\n",
    "text_net = args['text_net']\n",
    "if text_net == 'cnn':\n",
    "    lng_net = TextCNN(len(test.tokenizer.word_index) + 1, None)\n",
    "elif text_net == 'lstm':\n",
    "    lng_net = TextLSTM(len(test.tokenizer.word_index) + 1, None)\n",
    "else:\n",
    "    raise RuntimeError('invalid text_net')\n",
    "\n",
    "h_size=args['h_size']\n",
    "margin = args['margin']\n",
    "model_name = args['model_name']\n",
    "\n",
    "if model_name == 'ocr':\n",
    "    model = NonVisualNet(lng_net, h_size=h_size, margin=margin)\n",
    "elif model_name == 'ocr+vis':\n",
    "    att_net = AttentionNetWTL(h_size=100)\n",
    "    model = Net(lng_net, att_net)\n",
    "else:\n",
    "    raise RuntimeError\n",
    "\n",
    "chainer.serializers.load_npz(os.path.join(model_dir, 'model'), model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_tmp = '''\n",
    " <!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<title>Page Title</title>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "%s\n",
    "\n",
    "</body>\n",
    "</html> \n",
    "'''\n",
    "\n",
    "reverse_word_map = dict(map(reversed, test.tokenizer.word_index.items()))\n",
    "def get_raw_ocr(item):\n",
    "    raw_ocr = []\n",
    "    for x in item:\n",
    "        raw_ocr.append([reverse_word_map[idx] for idx in x[4]])\n",
    "    return raw_ocr\n",
    "\n",
    "if device is not None:\n",
    "    chainer.cuda.get_device_from_id(device).use()\n",
    "    model.to_gpu()\n",
    "\n",
    "results = {}\n",
    "b_size = 1\n",
    "\n",
    "with chainer.using_config('train', False), chainer.using_config('test', True), chainer.using_config('enable_backprop', False):\n",
    "    for i in range(0, len(test), b_size):\n",
    "        i = 74\n",
    "        item = test[i: i + b_size]\n",
    "        img_id = test.images[i:i+b_size]\n",
    "\n",
    "        with chainer.using_config('clean_description', False):\n",
    "            desc = [test.get_row_answer(j) for j in range(i, min(len(test)-1, i+b_size))]\n",
    "        \n",
    "        raw_ocr = get_raw_ocr(item)\n",
    "\n",
    "        batch = my_converter(item, device=device)\n",
    "        outputs = model.predict(*batch, layers=['dist'])\n",
    "        dist = outputs['dist']\n",
    "\n",
    "        dist.to_cpu()\n",
    "        dist = dist.data.ravel()\n",
    "        dist = np.reshape(dist, (-1, 15))\n",
    "\n",
    "\n",
    "        sort_i = dist.argsort(axis=1)\n",
    "        \n",
    "        # get ocr attention value\n",
    "        action, reason, ocr = batch[1], batch[2], batch[4]\n",
    "        a_att, r_att = get_ocr_att(ocr, action, reason)\n",
    "        a_att.to_cpu()\n",
    "        r_att.to_cpu()\n",
    "        \n",
    "        wc = a_att.shape[-2]\n",
    "        a_att_array = a_att.data.squeeze().reshape(-1, 15, wc)\n",
    "        r_att_array = r_att.data.squeeze().reshape(-1, 15, wc)\n",
    "            \n",
    "        \n",
    "        for im_i, des, s_i in zip(img_id, desc, sort_i):\n",
    "            results[im_i] = des[s_i[0]]\n",
    "        \n",
    "        body = get_result_html(img_id, a_att_array, r_att_array, raw_ocr, desc, sort_i)\n",
    "        \n",
    "        display_html(body, raw=True)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
